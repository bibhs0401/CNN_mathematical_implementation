{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter notebook demonstrates how to implement a Convolutional Neural Network (CNN) from scratch, using only basic libraries and no high-level frameworks for the core computations."
      ],
      "metadata": {
        "id": "WF_2ZHjJcuJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Importing Libraries**\n",
        "\n",
        "\n",
        "*   **TensorFlow**: Used here solely to load the MNIST dataset.\n",
        "*   **NumPy:** Provides support for large multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "WIOpWWS0c5SB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XskuXxodrYFs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Convolutional Layer**\n",
        "\n",
        "\n",
        "*   **Initialization**: The constructor initializes the number of kernels, kernel size, stride, bias, and the kernels themselves.\n",
        "*   **Partition Generator**: Generates partitions of the image to apply the convolution operation.\n",
        "\n",
        "\n",
        "*   **Forward Propagation**: Performs the convolution operation on the input image and returns the feature maps.\n",
        "*   **Backward Propagation**: Updates the kernels based on the gradients and learning rate.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VKUkr5ZKdNpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionLayers:\n",
        "  def __init__(self,kernel_num,kernel_size,stride = 1,bias = 1):\n",
        "\n",
        "    self.no_of_kernels = kernel_num\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.bias = bias\n",
        "    self.kernels = np.random.randn(kernel_num,kernel_size,kernel_size) / kernel_size**2\n",
        "\n",
        "  def partition_generator(self,input_img):\n",
        "    img_h,img_w = input_img.shape\n",
        "    self.img = input_img\n",
        "    for h in range(0,img_h-self.kernel_size+1,self.stride):\n",
        "      for w in range(0,img_w - self.kernel_size+1,self.stride):\n",
        "        slice = input_img[h:(h+self.kernel_size),w:(w+self.kernel_size)]\n",
        "        yield slice,h,w\n",
        "\n",
        "  def forward_prop(self,img):\n",
        "    img_h,img_w = img.shape\n",
        "    conv_output = np.zeros((img_h-self.kernel_size+1,img_w-self.kernel_size+1,self.no_of_kernels))\n",
        "    for sec,h,w in self.partition_generator(img):\n",
        "      conv_output[h,w] = np.sum(sec*self.kernels,axis = (1,2))\n",
        "    return conv_output\n",
        "\n",
        "  def backward_prop(self,dL_dZ,learning_rate):\n",
        "      dL_dk = np.zeros(self.kernels.shape)\n",
        "      for sec,h,w in self.partition_generator(self.img):\n",
        "        for f in range(self.no_of_kernels):\n",
        "          dL_dk += sec*dL_dZ[h,w,f]\n",
        "      self.kernels -= learning_rate*dL_dk\n",
        "      return dL_dk\n"
      ],
      "metadata": {
        "id": "2udjHrjvrgxX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Max Pooling Layer**\n",
        "MaxPool class performs the max pooling operation to reduce the spatial dimensions of the input feature maps."
      ],
      "metadata": {
        "id": "gw_j-UYAdx9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Initialization**: Initializes the pool size and stride.\n",
        "\n",
        "*   **Partition Generator**: Generates partitions of the image for pooling.\n",
        "\n",
        "\n",
        "*   **Forward Propagation:** Performs max pooling on the input feature maps.\n",
        "*   **Backward Propagation:** Distributes the gradients back through the pooling layer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OI8vNVAFeqqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool:\n",
        "  def __init__(self,pool_size,stride):\n",
        "    self.pool_size = pool_size\n",
        "    self.stride = stride\n",
        "\n",
        "  def partition_generator(self,img):\n",
        "    img_h,img_w = img.shape[0]//self.pool_size,img.shape[1]//self.pool_size\n",
        "    self.img = img\n",
        "    for h in range(0,img_h,self.stride):\n",
        "      for w in range(0,img_w,self.stride):\n",
        "        slice = img[(h*self.pool_size):(h*self.pool_size+self.pool_size),(w*self.pool_size):(w*self.pool_size+self.pool_size)]\n",
        "        yield slice,h,w\n",
        "\n",
        "  def forward_prop(self,img):\n",
        "    h,w,num_kernels = img.shape\n",
        "    max_pooled_out = np.zeros((h//self.pool_size,w//self.pool_size,num_kernels))\n",
        "    for slice,h,w in self.partition_generator(img):\n",
        "      max_pooled_out[h,w] = np.amax(slice,axis = (0,1))\n",
        "    return max_pooled_out\n",
        "\n",
        "  def backward_prop(self,dL_dZ):\n",
        "\n",
        "    dL_dk = np.zeros(self.img.shape)\n",
        "    for patch,h,w in self.partition_generator(self.img):\n",
        "      h0, w0, num_kernels = patch.shape\n",
        "      max_val = np.amax(patch, axis=(0,1))\n",
        "      for idx_h in range(h0):\n",
        "        for idx_w in range(w0):\n",
        "          for idx_k in range(num_kernels):\n",
        "            if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "              dL_dk[h*self.pool_size+idx_h, w*self.pool_size+idx_w, idx_k] = dL_dZ[h,w,idx_k]\n",
        "      return dL_dk\n"
      ],
      "metadata": {
        "id": "ikgefd_Wrnho"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Fully Connected and Softmax Layer**\n",
        "The FullyCon_SoftmaxLayer class implements the fully connected layer followed by a softmax activation, which is used for classification.\n",
        "\n",
        "*   **Initialization**: Initializes weights and biases.\n",
        "*   **Dense Layer**: Flattens the input and applies the fully connected layer.\n",
        "\n",
        "\n",
        "*   **Softmax Output**: Computes the softmax activation.\n",
        "*   **Forward Propagation**: Combines the dense layer and softmax operations.\n",
        "\n",
        "\n",
        "*   **Backward Propagation**: Updates the weights and biases based on the gradients and learning rate.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HLg_0M4Ce8jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyCon_SoftmaxLayer:\n",
        "    def __init__(self, input_units, output_units):\n",
        "        self.weight = np.random.randn(input_units, output_units) / input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "        self.output = None\n",
        "\n",
        "    def _dense_layer(self, image):\n",
        "        self.original_shape = image.shape\n",
        "        image_flattened = image.flatten()\n",
        "        self.flattened_input = image_flattened\n",
        "        dense_output = np.dot(image_flattened, self.weight) + self.bias\n",
        "        self.output = dense_output\n",
        "        return dense_output\n",
        "\n",
        "    def _softmax_out(self, dense_out):\n",
        "        softmax_output = np.exp(dense_out) / np.sum(np.exp(dense_out), axis=0)\n",
        "        return softmax_output\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        dense_out = self._dense_layer(image)\n",
        "        softmax_output = self._softmax_out(dense_out)\n",
        "        return softmax_output\n",
        "\n",
        "    def backward_prop(self, dL_dz, lr):\n",
        "        for i, gradient in enumerate(dL_dz):\n",
        "            if gradient == 0:\n",
        "                continue\n",
        "            transformation_eq = np.exp(self.output)\n",
        "            S_total = np.sum(transformation_eq)\n",
        "\n",
        "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "            dZ_dw = self.flattened_input\n",
        "            dZ_db = 1\n",
        "            dZ_dX = self.weight\n",
        "\n",
        "            dE_dZ = gradient * dY_dZ\n",
        "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "            dE_db = dE_dZ * dZ_db\n",
        "            dE_dX = dZ_dX @ dE_dZ\n",
        "\n",
        "            self.weight -= lr * dE_dw\n",
        "            self.bias -= lr * dE_db\n",
        "\n",
        "            return dE_dX.reshape(self.original_shape)"
      ],
      "metadata": {
        "id": "iQE_VIF8rsOY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Prediction**\n",
        "\n",
        "\n",
        "*   **Initialization:** Initializes the training parameters, datasets, and layers.\n",
        "*   **MNIST Execution:** Trains the model using the MNIST dataset.\n",
        "\n",
        "\n",
        "*   **Normal Execution:** Trains the model using the provided dataset.\n",
        "*   **Forward Propagation:** Computes the forward pass through the network.\n",
        "\n",
        "\n",
        "*   **Backward Propagation:** Updates the network parameters using backpropagation.\n",
        "*   **Training:** Trains the model on a single image-label pair.\n",
        "\n",
        "*   **Prediction:** Predicts the label for a given image.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PAvx5WSfZfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Train_Pred_Model:\n",
        "\n",
        "    def __init__(self, epochs=10, imgs=None, labels=None, layers=None, isMnist=True, train=True):\n",
        "        self.isMnist = isMnist\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.layers = layers\n",
        "        self.epochs = epochs\n",
        "\n",
        "        if self.isMnist and train:\n",
        "            self._Mnist_Exec()\n",
        "        elif train:\n",
        "            self._Normal_Exec()\n",
        "\n",
        "    def _Mnist_Exec(self):\n",
        "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "        X_train = X_train[:5000]\n",
        "        y_train = y_train[:5000]\n",
        "\n",
        "        layers = [\n",
        "            ConvolutionLayers(16, 3),\n",
        "            MaxPool(2, 2),\n",
        "            FullyCon_SoftmaxLayer(13*13*16, 10)\n",
        "        ]\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            print(f'Epoch {epoch + 1} -->')\n",
        "\n",
        "            permutation = np.random.permutation(len(X_train))\n",
        "            X_train = X_train[permutation]\n",
        "            y_train = y_train[permutation]\n",
        "\n",
        "            total_loss = 0\n",
        "            total_accuracy = 0\n",
        "            num_samples = len(X_train)\n",
        "\n",
        "            for image, label in zip(X_train, y_train):\n",
        "                loss, accuracy = self.train(image, label, layers)\n",
        "                total_loss += loss\n",
        "                total_accuracy += accuracy\n",
        "\n",
        "            average_loss = total_loss / num_samples\n",
        "            average_accuracy = total_accuracy / num_samples\n",
        "            print(f'Epoch {epoch + 1} --> average loss: {average_loss}, average accuracy: {average_accuracy}')\n",
        "\n",
        "        self.layers = layers\n",
        "        return layers\n",
        "\n",
        "    def _Normal_Exec(self):\n",
        "        for epoch in range(self.epochs):\n",
        "            print(f'Epoch {epoch + 1} -->')\n",
        "\n",
        "            total_loss = 0\n",
        "            total_accuracy = 0\n",
        "            num_samples = len(self.imgs)\n",
        "\n",
        "            for image, label in zip(self.imgs, self.labels):\n",
        "                loss, accuracy = self.train(image, label, self.layers)\n",
        "                total_loss += loss\n",
        "                total_accuracy += accuracy\n",
        "\n",
        "            average_loss = total_loss / num_samples\n",
        "            average_accuracy = total_accuracy / num_samples\n",
        "            print(f'Epoch {epoch + 1} --> average loss: {average_loss}, average accuracy: {average_accuracy}')\n",
        "\n",
        "        return self.layers\n",
        "\n",
        "    def _forward(self, img, label, layers):\n",
        "        output = img / 255.\n",
        "        for layer in layers:\n",
        "            output = layer.forward_prop(output)\n",
        "        loss = -np.log(output[label])\n",
        "        acc = 1 if np.argmax(output) == label else 0\n",
        "        return output, loss, acc\n",
        "\n",
        "    def _backprop(self, gradients, layers, lr=0.01):\n",
        "        grad = gradients\n",
        "        for layer in layers[::-1]:\n",
        "            if isinstance(layer, (ConvolutionLayers, FullyCon_SoftmaxLayer)):\n",
        "                grad = layer.backward_prop(grad, lr)\n",
        "            else:\n",
        "                grad = layer.backward_prop(grad)\n",
        "        return grad\n",
        "\n",
        "    def train(self, img, label, layers, lr=0.05):\n",
        "        output, loss, acc = self._forward(img, label, layers)\n",
        "        gradient = np.zeros(10)\n",
        "        gradient[label] = -1 / output[label]\n",
        "        grad = self._backprop(gradient, layers, lr)\n",
        "        return loss, acc\n",
        "\n",
        "    def predict(self, img, layers):\n",
        "        output = img / 255.\n",
        "        for layer in layers:\n",
        "            output = layer.forward_prop(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "IF4YAWkErao8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = Train_Pred_Model(epochs = 10,train = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV3d5VPJr-Vp",
        "outputId": "f686eef1-f8cb-484b-9487-53f726fddbf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1 -->\n",
            "Epoch 1 --> average loss: 0.6493965567791369, average accuracy: 0.8202\n",
            "Epoch 2 -->\n",
            "Epoch 2 --> average loss: 0.39215466936620375, average accuracy: 0.889\n",
            "Epoch 3 -->\n",
            "Epoch 3 --> average loss: 0.3400028914204129, average accuracy: 0.9038\n",
            "Epoch 4 -->\n",
            "Epoch 4 --> average loss: 0.30748923353655894, average accuracy: 0.9114\n",
            "Epoch 5 -->\n",
            "Epoch 5 --> average loss: 0.28485756794528366, average accuracy: 0.9194\n",
            "Epoch 6 -->\n",
            "Epoch 6 --> average loss: 0.26822254651200855, average accuracy: 0.9248\n",
            "Epoch 7 -->\n",
            "Epoch 7 --> average loss: 0.25504665967077245, average accuracy: 0.9268\n",
            "Epoch 8 -->\n",
            "Epoch 8 --> average loss: 0.24463324857984717, average accuracy: 0.9322\n",
            "Epoch 9 -->\n",
            "Epoch 9 --> average loss: 0.23267339963035139, average accuracy: 0.934\n",
            "Epoch 10 -->\n",
            "Epoch 10 --> average loss: 0.22357623695248216, average accuracy: 0.9388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Shuffle indices\n",
        "shuffled_indices = np.random.permutation(len(X_test))\n",
        "\n",
        "# Select a sample image from the test dataset\n",
        "sample_index = shuffled_indices[0]\n",
        "sample_image = X_test[sample_index]\n",
        "sample_label = y_test[sample_index]\n",
        "\n",
        "# Display the sample image\n",
        "plt.imshow(sample_image, cmap='gray')\n",
        "plt.title(f'True Label: {sample_label}')\n",
        "plt.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image = sample_image / 255.\n",
        "\n",
        "# Get the trained layers from the model\n",
        "trained_layers = Model.layers\n",
        "\n",
        "# Run prediction\n",
        "prediction_output = Model.predict(normalized_image, trained_layers)\n",
        "\n",
        "# Get the predicted class\n",
        "predicted_class = np.argmax(prediction_output)\n",
        "\n",
        "print(f'Predicted class: {predicted_class}')\n"
      ],
      "metadata": {
        "id": "A4QA9Re9sHNX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "0c7ef858-7bd0-4f01-8819-5bbe16e5beda"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSGuVlkppYUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}